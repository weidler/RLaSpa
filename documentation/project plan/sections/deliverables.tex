\section{Deliverables}
\label{sec:deliverables}

What we want to deliver is an agent that we trained using reinforcement learning. The training environment that we will use is the OpenAI Gym \citep{openaigym}. This enables us to implement different approaches with varying difficulty. A relative easy approach will be to train the agent on sinusoidal tasks such as a cartpole task, a mountain car task or a pendulum task. For this, we will use the internal state representation at first, later, if possible, transforming these problems to a visual state representation. 

A second deliverable will be an agent that is able to play Atari games using pixels as input. Although the OpenAI Gym framework also supports this, it will be harder to implement because we will need a lot more time to train an agent. This renders debugging very time consuming. Furthermore, none of us has experience with pixel based input data, which will make constructing the needed neural network difficult.

Since we want to use a latent space for transfer learning we will need to deliver a representation learner. This learner will be based on an autoencoder model, more precisely on a variational autoencoder. The states that were used for training the VAE should be encoded in the learned representation, which in turn could be reused for future work.

Most importantly, we will deliver a method for transfer learning and an implementation of it. We will show that it is possible to learn from previous tasks and use knowledge from those to achieve a better performance in another related task. We will show this using sinusoidal tasks as well as Atari games. These trained models will be available for demonstration purposes.

Furthermore, the results will be compared using different metrics, showing their different kind of strengths such as jumpstart, convergence and overall performance. Additionally, a qualitative analysis of the learned representation will be given. This analysis will investigate what kind of features are still present in the latent space and how an agent can learn from these representations.
