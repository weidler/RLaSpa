\section{Deliverables}
\label{sec:deliverables}

One of our deliverables is an agent trained using reinforcement learning. The training environment that we will use is the OpenAI Gym \citep{openaigym}. This enables us to implement different approaches with varying difficulty. A relative easy approach will be to train the agent on sinusoidal tasks such as a cartpole task, a mountain car task or a pendulum task. For this, we will use the internal state representation at first, later, if possible, transforming these problems to a visual state representation. 

A second deliverable will be an agent that is able to play Atari games based on raw pixel input. Although the OpenAI Gym framework also supports this, it will be harder to implement because we will need a lot more time to train an agent. This renders debugging very time consuming. Furthermore, none of us has experience with pixel based input data, which will make constructing the needed neural network difficult.

Since we want to use a latent space for transfer learning, we will need to deliver a representation learner. This learner will be based on an autoencoder model, more precisely on a variational autoencoder. The states that were used for training the VAE should be encoded in the learned representation, which in turn could be reused for future work.

Most importantly, we will deliver a method for transfer learning and an implementation of it. 
We will provide an experiment-supported conclusion on the possibility of learning from previous tasks and use knowledge gained there to achieve a better performance in another related task. 
Experiments on sinusoidal tasks as well as Atari games will be conducted and their results presented and analyzed. These trained models will be available for demonstration purposes.

Furthermore, the results will be compared using metrics measuring different aspects of performance improvement, %, showing their different kind of strengths 
such as jumpstart, convergence and overall performance. Additionally, a qualitative analysis of the learned representation will be given. This analysis will investigate what kind of features are still present in the latent space and how an agent can learn from these representations.
