\documentclass{article}
\usepackage[natbib=true,backend=bibtex,style=authoryear,language=english]{biblatex}
\usepackage[utf8]{inputenc}
\addbibresource{references.bib}

\title{Concepts and approach}
\author{Adri√°n R.G, Alessandro Scoppio}
\date{October 2018}

\begin{document}

\maketitle

\section{Concepts and approach}

The development of the project will require the use of different deep learning algorithms in order to tackle the final goal. Tasks like the feature extraction from the Atari frames, the generation of the latent space and the finding and training of the agent policy will be handled by deep learning techniques.

When dealing with Atari games, the problem of constructing features-vectors from raw pixels can be addressed using \textbf{Convolutional neural networks (CNNs)}.
CNNs, are a class of neural networks designed to process ``grid-like topology data'' (\cite{goodfellow2016deep}) like images or sounds signals. CNNs allow to ``abstract'' features from the raw pixels matrix using an operation called \textit{convolution}, a special kind of linear operation. Each feature will be represented by a \textit{filter}: a vector of weights and the respective bias that are incrementally adjusted to ``learn'' how to correctly extract that specific feature (e.g. a square shape). 
Furthermore, by using gameplay frames as input for the CNN, we assure that each task to later embed in the latent space has the same data structure for the state space.  


%\textbf{Convolutional neural networks (CNNs)} are a category of artificial neural networks designed to process ``grid-like topology data'' (\cite{goodfellow2016deep}) like images or sounds signals. Its architecture, that take advantage of the topology of the input, arrange the neurons in three dimensions: width, height and depth. 

% The name of this kind of neural networks comes from the operation in which they are based, the convolution, which is a special kind of linear operation. CNNs architecture is formed by four main layers:

% \begin{itemize}
%     \item Convolutional layer.
%     \item ReLu layer.
%     \item Pooling layer.
%     \item Classification layer.
% \end{itemize}

% The convolution layer is the main part of the CNNs, being in charge of detecting the features in the data by the use of filters. To im   prove the speed of the training, convolution layers are followed by the rectified linear units (ReLu) layer, that acts as a rectifier function.

% The functionality of the pooling layer is reduce the spatial size of the representation with the objective of decrease the parameters in the network and the computation required. Finally, the last part of the network is the fully connected layer, which performs the classification task.

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

In order to generate the latent space, \textbf{autoencoders} will be used. An autoencoder is a neural network formed by two parts: the encoder, that converts the input to a dense and smaller representation and the decoder, that rebuild the input from the representation. The main application for autoencoders is the dimensionality reduction (\cite{Hinton504}), where the encoder learns to preserve the meaningful attributes of the input and generates a lower dimensional representation that is saved in the \textbf{latent space}. 

As we work with different tasks, the latent space will be the place where we aim to save a generalized representation of the state spaces. To create a continuous latent space, that could allow transfer among task, a \textbf{variational autoencoder (VAE)} will be used. This kind of neural network use probability distributions to describe each feature, allowing interpolation and random sampling in the data. Moreover, VAEs are trained with \textbf{gradient based methods} which gives a better control over the latent space representation (\cite{goodfellow2016deep}) and can be used to generate representations with disentangled factors (\cite{2016arXiv160605579H}).

To achieve transfer learning, the agent will learn from the generalisation of the states stored in the latent space using deep reinforcement learning techniques. This algorithms will be used with the objective of creating an agent that will be capable of detecting similar states and situations that occurs on tasks and act in a similar way in each of them. 



% Concepts:
% \begin{itemize}
% \item Existing Technologies
% \item Methods
% \item Terminology
% \end{itemize}

% Approach:
% \begin{itemize}
% \item What will you be doing with these technologies?
% \item How will you apply them?
% \end{itemize}

\end{document}
