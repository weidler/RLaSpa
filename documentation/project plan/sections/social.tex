\section{Social Impact}

While reinforcement learning proved its effectiveness in diverse areas ranging from chemistry (\cite{zhou2017optimizing}) to games (\cite{silver2017mastering}), solving complex problems typically require costly computational resources. This could be a factor blocking individuals or smaller organizations from utilizing such techniques. However, if knowledge learnt on one task can be reused on other related ones, this entrance barrier could be greatly lowered. Since this research project focuses on transferring knowledge across tasks, the proposed method, if proven successful, could make reinforcement learning techniques more accessible and usable.
%Furthermore, if changes happen in the environment the learning process has to restart from the beginning, requiring additional time and resources. 

A concern about the the topic of this project, however, could be that knowledge transferring is one of the first steps towards ``general" artificial intelligence. Several prominent scholars and industry leaders warned about potential of reinforcement-learnt agents that can manipulate or control their reward signals (\cite{russell2016research}). However, since existing research on transfer learning in reinforcement learning were generally validated on simple simulated physical games or Atari games, we do not consider this risk sufficiently realistic to be relevant. 

%This main disadvantage of reinforcement learning actually push away the possibility of any kind of "general purpose" artificial intelligence, or at least it makes it very difficult. Finding a solution that allows knowledge transferring would be one of the first steps towards a more generic and context free form of "intelligence". 

%If on the one hand achieving a good transfer learning between reasonably different task would be a big advance in state-of-the-art research, on the other hand we should also be aware of possible future risks. As stated in "Research Priorities for Robust and Beneficial Artificial Intelligence" - open letter in the artificial intelligence world signed by scientists of the caliber of Stephen Hawking, Elon Musk and Yann LeCun - "Reinforcement learning raises its own problems: when systems become very capable and general, then an effect similar to Goodhartâ€™s Law is likely to occur, in which sophisticated agents attempt to manipulate or directly control their reward signals" (\cite{russell2016research}). %Also referenced in superintelligence the book
