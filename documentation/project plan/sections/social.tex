\section{Social Impact}

Reinforcement Learning proved its effectiveness in various areas, from chemistry (\cite{zhou2017optimizing}), to games (\cite{silver2017mastering}). Nonetheless, these goals have been achieve using incredibly expensive and powerful hardware, as well as requiring fairly long training time. Furthermore, if changes happen in the environment the learning process has to restart from the beginning, requiring additional time and resources. 

This main disadvantage of reinforcement learning actually push away the possibility of any kind of "general purpose" artificial intelligence, or at least it makes it very difficult. Finding a solution that allows knowledge transferring would be one of the first steps towards a more generic and context free form of "intelligence". 

If on the one hand achieving a good transfer learning between reasonably different task would be a big advance in state-of-the-art research, on the other hand we should also be aware of possible future risks. As stated in "Research Priorities for Robust and Beneficial Artificial Intelligence" - open letter in the artificial intelligence world signed by scientists of the caliber of Stephen Hawking, Elon Musk and Yann LeCun - "Reinforcement learning raises its own problems: when systems become very capable and general, then an effect similar to Goodhartâ€™s Law is likely to occur, in which sophisticated agents attempt to manipulate or directly control their reward signals" (\cite{russell2016research}). %Also referenced in superintelligence the book
