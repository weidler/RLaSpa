\section{Concepts and approach}

The development of the project will require of the use of different deep learning algorithms in order to tackle the final goal. Tasks like the generation of the latent space, the finding and training of the agent policy or the recognition of the Atari frames will be handled by deep learning techniques.

In order to generate the latent space, \textbf{autoencoders} will be used. An autoencoder is a neural network formed by two parts: the encoder, that converts the input to a dense and smaller representation and the decoder, that rebuild the input from the representation. The main application for autoencoders is the dimensionality reduction (\cite{Hinton504}), where the encoder learns to preserve the meaningful attributes of the input and generates a lower dimensional representation that is saved in the \textbf{latent space}. This characteristics  

As we work with different tasks, the latent space will be the place where we aim to save a generalized representation of the states. To create a continuous latent space, that could be shared among the tasks, a \textbf{variational autoencoder (VAEs)} will be used. This kind of neural network use probability distributions to describe each feature, allowing interpolation and random sampling in the data. Moreover, VAEs are trained with \textbf{gradient based methods} which gives a better control over the latent space representation (\cite{goodfellow2016deep}) and generates representations with disentangled factors (\cite{2016arXiv160605579H}).

\textbf{Convolutional neural networks (CNNs)} are a category of artificial neural networks designed to process ``grid-like topology data'' (\cite{goodfellow2016deep}) like images or sounds signals. Its architecture, that take advantage of the topology of the input, arrange the neurons in three dimensions: width, height and depth. 

The name of this kind of neural networks comes from the operation in which they are based, the convolution, which is a special kind of linear operation. CNNs architecture is formed by four main layers:

\begin{itemize}
    \item Convolutional layer.
    \item ReLu layer.
    \item Pooling layer.
    \item Classification layer.
\end{itemize}

The convolution layer is the main part of the CNNs, being in charge of detecting the features in the data by the use of filters. To improve the speed of the training, convolution layers are followed by the rectified linear units (ReLu) layer, that acts as a rectifier function.

The functionality of the pooling layer is reduce the spatial size of the representation with the objective of decrease the parameters in the network and the computation required. Finally, the last part of the network is the fully connected layer, which performs the classification task.



\textbf{Latent Space (LS)} is the space in which information generated by the encoder lies. It contains the compressed representation of the input that can be used by the decoder to regenerate the data. 

\hrulefill

How will you be tackling/solving this?



Concepts:
\begin{itemize}
\item Existing Technologies
\item Methods
\item Terminology
\end{itemize}

Approach:
\begin{itemize}
\item What will you be doing with these technologies?
\item How will you apply them?
\end{itemize}